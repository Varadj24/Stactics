{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8937b9ad-6794-4b2d-9eca-87b94ec68c9c",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact \n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f40963-4b33-4076-b2b9-59b701139dcf",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means across multiple groups to determine if there are any statistically significant differences. However, ANOVA comes with certain assumptions, and violations of these assumptions can impact the validity of the results. The key assumptions for ANOVA are:\n",
    "\n",
    "1. **Normality of Residuals:**\n",
    "   - **Assumption:** The residuals (the differences between observed and predicted values) should be normally distributed.\n",
    "   - **Violation Example:** If the residuals deviate significantly from a normal distribution, it can affect the accuracy of the p-values and confidence intervals.\n",
    "\n",
    "2. **Homogeneity of Variances (Homoscedasticity):**\n",
    "   - **Assumption:** The variances of the residuals should be roughly equal across all groups.\n",
    "   - **Violation Example:** If the variances are not equal, it can lead to unequal influence of different groups on the overall test, affecting the validity of the results.\n",
    "\n",
    "3. **Independence of Observations:**\n",
    "   - **Assumption:** Observations in one group should be independent of observations in other groups.\n",
    "   - **Violation Example:** If there is dependency between observations, it can lead to biased estimates and incorrect conclusions.\n",
    "\n",
    "4. **Random Sampling:**\n",
    "   - **Assumption:** Data should be collected through a random sampling process.\n",
    "   - **Violation Example:** If sampling is not random, the results might not generalize well to the larger population.\n",
    "\n",
    "**Examples of Violations and Their Impact:**\n",
    "1. **Non-Normality:**\n",
    "   - **Impact:** If residuals are not normally distributed, the p-values and confidence intervals may be inaccurate, leading to incorrect conclusions about group differences.\n",
    "\n",
    "2. **Heteroscedasticity:**\n",
    "   - **Impact:** Unequal variances can affect the precision of the estimates and increase the risk of Type I errors (false positives) or Type II errors (false negatives).\n",
    "\n",
    "3. **Dependency:**\n",
    "   - **Impact:** If observations are not independent, it can violate the assumption of independence, potentially leading to biased estimates and incorrect inferences.\n",
    "\n",
    "4. **Non-Random Sampling:**\n",
    "   - **Impact:** Results might not be generalizable to the larger population if the sampling process is not random, limiting the external validity of the study.\n",
    "\n",
    "Researchers should assess these assumptions before conducting ANOVA and consider alternative methods or transformations if the assumptions are violated. Techniques like robust ANOVA or non-parametric tests may be more suitable in the presence of severe violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86da888-5c46-4d7b-b2b4-9b0d1f3856d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd75c439-65a4-46a7-abea-865abd7db1c9",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5480e6ee-76a3-4ea1-b778-d468dde851cc",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means across multiple groups. There are three main types of ANOVA, each suited for different situations:\n",
    "\n",
    "1. **One-Way ANOVA:**\n",
    "   - **Use Case:** Used when comparing means across two or more independent groups (levels) for a single independent variable (factor).\n",
    "   - **Example:** Testing if there is a significant difference in the average scores of students exposed to different teaching methods (e.g., Method A, Method B, Method C).\n",
    "\n",
    "2. **Two-Way ANOVA:**\n",
    "   - **Use Case:** Used when comparing means across two independent variables (factors) simultaneously, each with two or more levels.\n",
    "   - **Example:** Assessing the impact of both teaching method (e.g., Method A, Method B) and study time (e.g., Low, High) on student exam scores. It allows examining the main effects of each factor as well as their interaction.\n",
    "\n",
    "3. **Repeated Measures ANOVA:**\n",
    "   - **Use Case:** Used when comparing means of related groups, such as repeated measurements on the same subjects or matched pairs.\n",
    "   - **Example:** Assessing the impact of a drug treatment over time, where each participant is measured at different time points (e.g., baseline, after 1 week, after 2 weeks).\n",
    "\n",
    "**Situational Guidelines:**\n",
    "- **One-Way ANOVA:** Choose this when dealing with a single independent variable and more than two levels or groups. It helps determine if there are any significant differences in means.\n",
    "  \n",
    "- **Two-Way ANOVA:** Choose this when dealing with two independent variables to examine the main effects of each variable and their interaction. It allows for more complex experimental designs.\n",
    "\n",
    "- **Repeated Measures ANOVA:** Choose this when dealing with related groups or repeated measurements on the same subjects. It's suitable for longitudinal studies or experiments where the same individuals are measured under different conditions.\n",
    "\n",
    "Selecting the appropriate type of ANOVA depends on the study design and the specific research questions being addressed. Researchers should carefully consider the nature of their data and experimental setup to choose the most suitable ANOVA method for their analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0937d-9e4c-4163-b909-920f6d9c6c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76a2b623-ba75-4098-bd78-79f934d2f333",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1ab04-afc2-4a0e-9a90-2be99a89a9d4",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) refers to the decomposition of the total variability observed in the data into different sources. Understanding this concept is crucial as it helps in attributing the total variability to specific factors, allowing researchers to assess the significance of these factors in explaining the variation in the dependent variable. The partitioning is typically represented as:\n",
    "\n",
    "\\[ \\text{Total Variability} = \\text{Variability Due to Treatment (or Group)} + \\text{Residual Variability} \\]\n",
    "\n",
    "1. **Variability Due to Treatment (or Group):**\n",
    "   - Represents the differences among the group means. It reflects the variation caused by the independent variable (treatment or factor) being studied.\n",
    "   - Also known as the \"between-group\" variability.\n",
    "   - Calculated as the sum of squared deviations of each group mean from the overall mean, weighted by the sample size of each group.\n",
    "\n",
    "2. **Residual Variability (Error):**\n",
    "   - Represents the differences within each group or the unexplained variation.\n",
    "   - Also known as the \"within-group\" or \"error\" variability.\n",
    "   - Calculated as the sum of squared deviations of individual observations from their respective group means.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "- **Assessing Treatment Effect:** It helps in determining whether there are significant differences among the group means. If the variability due to treatment is much larger than the residual variability, it suggests that the treatment has a significant effect.\n",
    "\n",
    "- **Interpreting F-Statistic:** In ANOVA, the F-statistic is calculated as the ratio of the variability due to treatment to the residual variability. A large F-statistic indicates that the treatment effect is significant.\n",
    "\n",
    "- **Identifying Sources of Variation:** It allows researchers to identify and quantify the contribution of different factors to the total variability in the data, aiding in the interpretation of study results.\n",
    "\n",
    "- **Optimizing Experimental Design:** Understanding the partitioning of variance can guide researchers in designing experiments that maximize the ability to detect treatment effects by minimizing residual variability.\n",
    "\n",
    "In summary, partitioning variance in ANOVA is crucial for assessing the impact of different factors on the variability observed in the data. It provides insights into the sources of variation and allows for more informed interpretations of study results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f908955-a5ee-47e4-9744-562ad951adb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38f7ceb2-550c-4342-be35-38cd6770e4bc",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual \n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9c3d86-81d3-4054-bdaa-dc50e327c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 534.9333333333333\n",
      "Explained Sum of Squares (SSE): 449.73333333333335\n",
      "Residual Sum of Squares (SSR): 85.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data for three groups\n",
    "group1 = np.array([15, 12, 14, 17, 19])\n",
    "group2 = np.array([22, 18, 25, 20, 23])\n",
    "group3 = np.array([28, 30, 25, 32, 29])\n",
    "\n",
    "# Combine data from all groups\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "mean_group3 = np.mean(group3)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "sse = len(group1) * (mean_group1 - overall_mean)**2 + \\\n",
    "      len(group2) * (mean_group2 - overall_mean)**2 + \\\n",
    "      len(group3) * (mean_group3 - overall_mean)**2\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr_group1 = np.sum((group1 - mean_group1)**2)\n",
    "ssr_group2 = np.sum((group2 - mean_group2)**2)\n",
    "ssr_group3 = np.sum((group3 - mean_group3)**2)\n",
    "ssr = ssr_group1 + ssr_group2 + ssr_group3\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c409a-957c-4a02-82c6-dccb7c33d560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bd2ecd0-d063-43b8-a8c5-d4f6c585b280",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e49bed-206b-4964-a6b6-b71d170592f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3e77a-1d36-423c-8b47-55c681744104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Sample data for a 2x3 design (two factors with two and three levels, respectively)\n",
    "data = np.array([\n",
    "    [12, 15, 18],\n",
    "    [16, 14, 20],\n",
    "    [10, 13, 16],\n",
    "    [25, 22, 24],\n",
    "    [28, 26, 30]\n",
    "])\n",
    "\n",
    "# Calculate the means for each factor and the overall mean\n",
    "mean_total = np.mean(data)\n",
    "mean_factor1 = np.mean(data, axis=0)\n",
    "mean_factor2 = np.mean(data, axis=1)\n",
    "\n",
    "# Calculate the main effects\n",
    "main_effect_factor1 = np.sum((mean_factor1 - mean_total)**2) * len(data[0])\n",
    "main_effect_factor2 = np.sum((mean_factor2 - mean_total)**2) * len(data)\n",
    "\n",
    "# Calculate the interaction effect\n",
    "interaction_effect = np.sum((data - mean_factor1 - mean_factor2 + mean_total)**2)\n",
    "\n",
    "# Degrees of freedom for factors and interaction\n",
    "df_factor1 = len(data) - 1\n",
    "df_factor2 = len(data[0]) - 1\n",
    "df_interaction = (len(data) - 1) * (len(data[0]) - 1)\n",
    "\n",
    "# Mean squares\n",
    "ms_factor1 = main_effect_factor1 / df_factor1\n",
    "ms_factor2 = main_effect_factor2 / df_factor2\n",
    "ms_interaction = interaction_effect / df_interaction\n",
    "\n",
    "# F-ratios\n",
    "f_ratio_factor1 = ms_factor1 / ms_interaction\n",
    "f_ratio_factor2 = ms_factor2 / ms_interaction\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n",
    "print(\"\\nDegrees of Freedom:\")\n",
    "print(\"Factor 1:\", df_factor1)\n",
    "print(\"Factor 2:\", df_factor2)\n",
    "print(\"Interaction:\", df_interaction)\n",
    "print(\"\\nMean Squares:\")\n",
    "print(\"Factor 1:\", ms_factor1)\n",
    "print(\"Factor 2:\", ms_factor2)\n",
    "print(\"Interaction:\", ms_interaction)\n",
    "print(\"\\nF-ratios:\")\n",
    "print(\"Factor 1:\", f_ratio_factor1)\n",
    "print(\"Factor 2:\", f_ratio_factor2)\n",
    "\n",
    "# P-values (using the cumulative distribution function (1 - cdf) of the F-distribution)\n",
    "p_value_factor1 = 1 - f.cdf(f_ratio_factor1, df_factor1, df_interaction)\n",
    "p_value_factor2 = 1 - f.cdf(f_ratio_factor2, df_factor2, df_interaction)\n",
    "\n",
    "print(\"\\nP-values:\")\n",
    "print(\"Factor 1:\", p_value_factor1)\n",
    "print(\"Factor 2:\", p_value_factor2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05355a-cb76-4433-830b-d3c8939c5d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c54420c-13e3-48ba-96ec-cfb4083d21eb",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. \n",
    "What can you conclude about the differences between the groups, and how would you interpret these \n",
    "results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc7ea5-76a9-4a3d-b0ae-da877400fd2c",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are any statistically significant differences between the means of three or more independent groups. The p-value associated with the F-statistic helps determine the statistical significance of the observed differences. Here's how to interpret the results:\n",
    "\n",
    "1. **Null Hypothesis (H0):**\n",
    "   - The null hypothesis in ANOVA is that there are no significant differences between the means of the groups.\n",
    "\n",
    "2. **Alternative Hypothesis (H1):**\n",
    "   - The alternative hypothesis is that at least one group mean is significantly different from the others.\n",
    "\n",
    "3. **Interpretation:**\n",
    "   - If the p-value is less than the chosen significance level (commonly 0.05), you reject the null hypothesis.\n",
    "   - If the p-value is greater than the significance level, you fail to reject the null hypothesis.\n",
    "\n",
    "In your example:\n",
    "- F-statistic = 5.23\n",
    "- p-value = 0.02\n",
    "\n",
    "**Interpretation:**\n",
    "- The p-value (0.02) is less than the commonly chosen significance level of 0.05.\n",
    "- Therefore, you reject the null hypothesis.\n",
    "\n",
    "**Conclusion:**\n",
    "The results suggest that there are statistically significant differences between the means of at least two groups. However, the ANOVA itself does not tell you which specific groups are different. To identify which groups are different, post hoc tests or pairwise comparisons (e.g., Tukey's HSD test) may be conducted.\n",
    "\n",
    "In summary, based on the obtained F-statistic and p-value, you have evidence to suggest that there are significant differences between the groups. The next step would involve further analyses to determine which specific groups are different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd2e3b-dad0-442d-8ee6-4fa7311c04dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a85da80e-d5fd-4811-9326-f436dea6fa35",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential \n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8e641-45aa-49a1-b709-e54518f91df4",
   "metadata": {},
   "source": [
    "Handling missing data in repeated measures ANOVA is an important consideration to ensure the validity and reliability of the analysis. There are several methods to handle missing data, and the choice of method can impact the results and conclusions drawn from the analysis. Here are common approaches and potential consequences:\n",
    "\n",
    "### Handling Missing Data in Repeated Measures ANOVA:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion):**\n",
    "   - **Approach:** Exclude cases with missing data on any variable in the analysis.\n",
    "   - **Consequences:**\n",
    "      - Reduces the sample size, potentially leading to reduced statistical power.\n",
    "      - May introduce bias if the missing data is not completely at random.\n",
    "\n",
    "2. **Pairwise Deletion (Available Case Analysis):**\n",
    "   - **Approach:** Include all available data for each specific comparison, excluding cases with missing data only for the specific comparison being analyzed.\n",
    "   - **Consequences:**\n",
    "      - Maximizes the use of available data but may result in different sample sizes for different comparisons.\n",
    "      - Estimates for each comparison are based on different subsets of the data.\n",
    "\n",
    "3. **Imputation Techniques:**\n",
    "   - **Approach:** Estimate missing values based on observed data.\n",
    "   - **Consequences:**\n",
    "      - Introduces imputed (estimated) values, potentially affecting the variability and relationships in the data.\n",
    "      - The choice of imputation method (mean imputation, regression imputation, etc.) can impact results.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF):**\n",
    "   - **Approach:** Use the last observed value for a participant to replace missing values in subsequent measurements.\n",
    "   - **Consequences:**\n",
    "      - Assumes that the last observed value remains constant over time, which may not be accurate.\n",
    "      - May artificially reduce variability and skew results.\n",
    "\n",
    "### Potential Consequences of Using Different Methods:\n",
    "\n",
    "1. **Bias:**\n",
    "   - Different methods may introduce bias if the missing data mechanism is not completely at random. Imputation methods, in particular, may introduce bias if the imputation model is misspecified.\n",
    "\n",
    "2. **Precision and Power:**\n",
    "   - Complete case analysis and LOCF may result in reduced precision and statistical power compared to imputation methods. However, imputation introduces variability.\n",
    "\n",
    "3. **Validity of Results:**\n",
    "   - The choice of method may impact the validity of the results and the conclusions drawn from the analysis. Researchers should carefully consider the appropriateness of the chosen method for their specific data and research question.\n",
    "\n",
    "When handling missing data, it is essential to transparently report the method chosen, justify the choice based on the characteristics of the data, and consider the potential impact of missing data on the validity of the results. Sensitivity analyses with different missing data methods can help assess the robustness of the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387afc1-91f6-46de-9804-1bae4a9dab56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eae90cea-1953-41bb-b7a3-4803f6fad67b",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide \n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ead7d-ff1e-4b18-a798-3c6019c518af",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after Analysis of Variance (ANOVA) to identify specific group differences when the ANOVA indicates a significant overall effect but does not specify which groups are different from each other. Common post-hoc tests include:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD) Test:**\n",
    "   - **Use Case:** Suitable when comparing all possible pairs of group means.\n",
    "   - **When to Use:** After detecting a significant overall difference in ANOVA and you want to identify specific pairs of groups that differ from each other.\n",
    "\n",
    "2. **Bonferroni Correction:**\n",
    "   - **Use Case:** Controls the familywise error rate by adjusting the significance level.\n",
    "   - **When to Use:** Suitable when performing multiple pairwise comparisons to reduce the risk of Type I errors. It is more conservative but may be appropriate when conducting many comparisons.\n",
    "\n",
    "3. **Scheff√©'s Test:**\n",
    "   - **Use Case:** Suitable for comparing all possible combinations of means with unequal sample sizes.\n",
    "   - **When to Use:** After detecting a significant overall difference in ANOVA, especially when dealing with groups with different sample sizes.\n",
    "\n",
    "4. **Dunnett's Test:**\n",
    "   - **Use Case:** Used when comparing treatment groups to a control group.\n",
    "   - **When to Use:** Appropriate when there is a control group, and the interest is in determining which treatment groups differ from the control group.\n",
    "\n",
    "5. **Holm's Method:**\n",
    "   - **Use Case:** A step-down procedure that controls the familywise error rate.\n",
    "   - **When to Use:** Similar to Bonferroni, but Holm's method may have more power, especially when many comparisons are conducted.\n",
    "\n",
    "**Example Situation:**\n",
    "Suppose a researcher conducts a study to compare the effectiveness of four different teaching methods (A, B, C, D) on student performance. After performing a one-way ANOVA, the researcher finds a significant overall difference in means. Now, to identify which specific teaching methods differ from each other, the researcher might conduct post-hoc tests.\n",
    "\n",
    "- If the interest is in comparing all possible pairs of teaching methods, Tukey's HSD test could be used.\n",
    "- If there is a control group (e.g., traditional teaching method), Dunnett's test might be appropriate to compare each treatment group with the control group.\n",
    "- If multiple pairwise comparisons are being made, and controlling for the overall Type I error rate is crucial, the Bonferroni correction or Holm's method could be considered.\n",
    "\n",
    "In summary, the choice of post-hoc test depends on the specific research question, the structure of the experimental design, and the nature of the pairwise comparisons of interest. Researchers should select a post-hoc test that is appropriate for their study context and objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c43176-1f34-4cff-9fa1-0bdf4f371b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b36df3-9e8c-462d-b0a1-0d931703dbda",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from \n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python \n",
    "to determine if there are any significant differences between the mean weight loss of the three diets. \n",
    "Report the F-statistic and p-value, and interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2c67ec-ac2c-451b-b565-9e6c94545c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.61854911979148\n",
      "p-value: 1.5055246613126342e-21\n",
      "The mean weight loss is significantly different between at least two diets.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "diet_A = np.random.normal(loc=2, scale=1, size=50)\n",
    "diet_B = np.random.normal(loc=3, scale=1, size=50)\n",
    "diet_C = np.random.normal(loc=4, scale=1, size=50)\n",
    "\n",
    "# Combine data from all diets\n",
    "all_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create a grouping variable\n",
    "group_labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "if p_value < 0.05:\n",
    "    print(\"The mean weight loss is significantly different between at least two diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in mean weight loss between the diets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd822e-fe20-44a4-bb50-5551565d24c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0674353e-62e6-4f3c-8ed1-a144aa85521c",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to \n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They \n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to \n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or \n",
    "interaction effects between the software programs and employee experience level (novice vs. \n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f09bfa-f126-437a-b9dd-24b04b1b1285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df       sum_sq    mean_sq         F    PR(>F)\n",
      "C(Software)                 2.0     9.309580   4.654790  0.216246  0.805984\n",
      "C(Experience)               1.0    31.851905  31.851905  1.479736  0.227223\n",
      "C(Software):C(Experience)   2.0    52.479686  26.239843  1.219018  0.300694\n",
      "Residual                   84.0  1808.132913  21.525392       NaN       NaN\n",
      "\n",
      "Software Main Effect p-value: 0.8059837604808455\n",
      "Experience Main Effect p-value: 0.22722286070941342\n",
      "Interaction Effect p-value: 0.3006938566718389\n",
      "\n",
      "There is no significant main effect of software programs.\n",
      "There is no significant main effect of experience levels.\n",
      "There is no significant interaction effect between software programs and experience levels.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Generate sample data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "software_programs = ['Program A', 'Program B', 'Program C']\n",
    "experience_levels = ['Novice', 'Experienced']\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Software': np.random.choice(software_programs, size=90),\n",
    "    'Experience': np.random.choice(experience_levels, size=90),\n",
    "    'Time': np.random.normal(loc=20, scale=5, size=90)  # Replace with your actual time data\n",
    "})\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "formula = 'Time ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "model = ols(formula, data).fit()\n",
    "anova_table = anova_lm(model)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the results\n",
    "software_p_value = anova_table['PR(>F)']['C(Software)']\n",
    "experience_p_value = anova_table['PR(>F)']['C(Experience)']\n",
    "interaction_p_value = anova_table['PR(>F)']['C(Software):C(Experience)']\n",
    "\n",
    "print(\"\\nSoftware Main Effect p-value:\", software_p_value)\n",
    "print(\"Experience Main Effect p-value:\", experience_p_value)\n",
    "print(\"Interaction Effect p-value:\", interaction_p_value)\n",
    "\n",
    "# Interpret the results\n",
    "if software_p_value < 0.05:\n",
    "    print(\"\\nThere is a significant main effect of software programs.\")\n",
    "else:\n",
    "    print(\"\\nThere is no significant main effect of software programs.\")\n",
    "\n",
    "if experience_p_value < 0.05:\n",
    "    print(\"There is a significant main effect of experience levels.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of experience levels.\")\n",
    "\n",
    "if interaction_p_value < 0.05:\n",
    "    print(\"There is a significant interaction effect between software programs and experience levels.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between software programs and experience levels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38815902-8623-403a-aa5d-6bbb9ec828ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09a6380e-9d6d-4cbb-b4a2-b7344993be58",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test \n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the \n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a \n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores \n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which \n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2bd8e58-cdd4-4955-8005-0e47a2faaff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample t-Test:\n",
      "t-statistic: -3.0031208261723967\n",
      "p-value: 0.0033913185510394315\n",
      "\n",
      "The test scores are significantly different between the control and experimental groups.\n",
      "Proceeding with post-hoc test.\n",
      "\n",
      "Post-Hoc Test (Tukey's HSD):\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   5.4325 0.0034 1.8427 9.0224   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "control_group = np.random.normal(loc=75, scale=10, size=50)  # Replace with actual control group scores\n",
    "experimental_group = np.random.normal(loc=78, scale=10, size=50)  # Replace with actual experimental group scores\n",
    "\n",
    "# Conduct a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results\n",
    "print(\"Two-Sample t-Test:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nThe test scores are significantly different between the control and experimental groups.\")\n",
    "    print(\"Proceeding with post-hoc test.\")\n",
    "    \n",
    "    # Combine data for post-hoc test\n",
    "    all_data = np.concatenate([control_group, experimental_group])\n",
    "    group_labels = ['Control'] * 50 + ['Experimental'] * 50\n",
    "    \n",
    "    # Perform Tukey's HSD post-hoc test\n",
    "    tukey_result = pairwise_tukeyhsd(all_data, group_labels)\n",
    "    \n",
    "    # Print post-hoc results\n",
    "    print(\"\\nPost-Hoc Test (Tukey's HSD):\")\n",
    "    print(tukey_result)\n",
    "else:\n",
    "    print(\"\\nThe test scores are not significantly different between the control and experimental groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa6db7-69bb-4964-8add-d49f60ea114d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c88ec3cf-6adc-4e78-a135-2914a9598721",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three \n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store \n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any \n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901dba16-6411-4c8a-8011-f144e95ad2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA:\n",
      "F-statistic: 12.20952551797281\n",
      "p-value: 2.1200748140507065e-05\n",
      "\n",
      "The average daily sales are significantly different between at least two stores.\n",
      "\n",
      "Post-Hoc Test (Tukey's HSD):\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1  group2 meandiff p-adj   lower   upper  reject\n",
      "------------------------------------------------------\n",
      "Store A Store B  11.3397 0.0567 -0.2571 22.9365  False\n",
      "Store A Store C  24.0206    0.0 12.4238 35.6175   True\n",
      "Store B Store C  12.6809 0.0287  1.0841 24.2778   True\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "sales_store_A = np.random.normal(loc=100, scale=20, size=30)  # Replace with actual sales data for Store A\n",
    "sales_store_B = np.random.normal(loc=110, scale=20, size=30)  # Replace with actual sales data for Store B\n",
    "sales_store_C = np.random.normal(loc=120, scale=20, size=30)  # Replace with actual sales data for Store C\n",
    "\n",
    "# Combine data\n",
    "all_data = np.concatenate([sales_store_A, sales_store_B, sales_store_C])\n",
    "store_labels = ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Sales': all_data, 'Store': store_labels})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(sales_store_A, sales_store_B, sales_store_C)\n",
    "\n",
    "# Print ANOVA results\n",
    "print(\"One-Way ANOVA:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nThe average daily sales are significantly different between at least two stores.\")\n",
    "    \n",
    "    # Perform post-hoc test (Tukey's HSD)\n",
    "    tukey_result = pairwise_tukeyhsd(all_data, store_labels)\n",
    "    \n",
    "    # Print post-hoc results\n",
    "    print(\"\\nPost-Hoc Test (Tukey's HSD):\")\n",
    "    print(tukey_result)\n",
    "else:\n",
    "    print(\"\\nThe average daily sales are not significantly different between the stores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96723f-c48f-4d6c-8924-cdaed19536e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
